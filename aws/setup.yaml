AWSTemplateFormatVersion: 2010-09-09
Description: Paint For Me Template
Parameters:
  WebsiteBucketName:
    Type: String
    Description: S3 Bucket name for website
    Default: paint-for-me-website
  GitHubRepositoryURL:
    Type: String
    Description: URL for GitHub repository with website files
    Default: https://raw.githubusercontent.com/NowakArtur97/Paint-For-Me/main
  FilesToCopyFromGitHub:
    Type: String
    Description: Website files to copy from GitHub
    Default: index.html,style.css,answer.js,paint.js,topics.js
  FileWithAPIGatewayInvokeURL:
    Type: String
    Description: File with API Gateway invoke url to be reaplaced by lambda function
    Default: answer.js
  APIGatewayName:
    Type: String
    Default: paint-for-me-api
  APIGatewayStageName:
    Type: String
    AllowedPattern: "[a-z0-9]+"
    Default: prod
  APIGatewayOperationName:
    Type: String
    Default: paint-for-me
  ImagesBucketName:
    Type: String
    Description: S3 Bucket name for image files
    Default: paint-for-me-images
  MaxNumberOfLabels:
    Type: Number
    Description: Maximum number of labels for Amazon Rekognition
    Default: 20
  MinConfidence:
    Type: Number
    Description: Minimum confidence value for Amazon Rekognition
    Default: 10
Resources:
  WebsiteS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref WebsiteBucketName
      PublicAccessBlockConfiguration:
        BlockPublicAcls: false
      OwnershipControls:
        Rules:
          - ObjectOwnership: ObjectWriter
      WebsiteConfiguration:
        IndexDocument: index.html
        ErrorDocument: index.html
  WebsiteS3BucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref WebsiteS3Bucket
      PolicyDocument:
        Id: WebsiteS3BucketPolicy
        Version: 2012-10-17
        Statement:
          - Sid: PublicReadForGetBucketObjects
            Effect: Allow
            Principal: "*"
            Action: "s3:GetObject"
            Resource: !Sub "arn:aws:s3:::${WebsiteS3Bucket}/*"
  GitHubToS3LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: "/"
      Policies:
        - PolicyName: GitHubToS3LambdaFunctionPolicies
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - s3:PutObject
                Resource: !Sub "arn:aws:s3:::${WebsiteS3Bucket}/*"
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: "*"
  GitHubToS3LambdaInvoke:
    Type: AWS::CloudFormation::CustomResource
    DependsOn: GitHubToS3LambdaFunction
    Version: "1.0"
    Properties:
      ServiceToken: !GetAtt GitHubToS3LambdaFunction.Arn
  GitHubToS3LambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Runtime: python3.9
      Timeout: 120
      Handler: index.lambda_handler
      Role: !GetAtt GitHubToS3LambdaRole.Arn
      Environment:
        Variables:
          BUCKET_NAME: !Ref WebsiteS3Bucket
          GITHUB_URL: !Ref GitHubRepositoryURL
          FILES_TO_COPY: !Ref FilesToCopyFromGitHub
      Code:
        ZipFile: |
          import os
          import urllib.request
          import boto3
          from urllib.parse import urlparse
          import cfnresponse

          s3 = boto3.resource('s3')
          BUCKET_NAME = os.environ['BUCKET_NAME']
          GITHUB_URL = os.environ['GITHUB_URL']
          FILES_TO_COPY = os.environ['FILES_TO_COPY'].split(",")

          def save_to_local(url):
              urlPath = urlparse(url).path
              fileName = os.path.basename(urlPath)
              filePath = '/tmp/' + fileName
              urllib.request.urlretrieve(url, filePath)
              return filePath

          def copy_to_s3(url, contentType):
              filePath = save_to_local(url)
              fileName = os.path.basename(filePath)
              s3.Object(BUCKET_NAME, fileName).put(Body=open(filePath, 'rb'), ContentType=contentType)

          def resolve_content_type(file):
              extension = file.split(".")[1]
              if extension == "html":
                  return "text/html"
              elif extension == "css":
                  return "text/css"
              elif extension == "js":
                  return "text/javascript"
              elif extension == "py":
                  return "text/x-python"
              elif extension in ["jpeg", "jpg"]:
                  return "image/jpeg"
              elif extension == "png":
                  return "image/png"
              elif extension == "tiff":
                  return "image/tiff"
              elif extension == "bmp":
                  return "image/bmp"
              elif extension == "gif":
                  return "image/gif"
              elif extension in ["svg", "xml"]:
                  return "image/svg+xml"
              elif extension in ["mp3", "wav", "ogg"]:
                  return "audio/mpeg"
              elif extension == "pdf":
                  return "application/pdf"
              elif extension == "zip":
                  return "application/zip"
              elif extension == "yaml":
                  return "binary/octet-stream"
              else:
                  return "text/plain"

          def lambda_handler(event, context):
              responseData = {}
              requestType = event['RequestType']
              try:
                  if requestType == 'Create':
                      for fileToCopy in FILES_TO_COPY:
                          fileOnGitHub = GITHUB_URL + "/" + fileToCopy
                          print("File to copy: " + fileToCopy)
                          print("URL to file: " + fileOnGitHub)
                          contentType = resolve_content_type(fileToCopy)
                          copy_to_s3(fileOnGitHub, contentType)
                          print("Successfully copied file: " + fileToCopy + " to bucket: " + BUCKET_NAME)
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
              except Exception as e:
                  print("Exception when copying files from GitHub to S3 bucket: " + BUCKET_NAME)
                  print(e)
                  cfnresponse.send(event, context, cfnresponse.FAILED, responseData)
  APIGatewayDeployment:
    Type: AWS::ApiGateway::Deployment
    DependsOn: APIGatewayMethod
    Properties:
      RestApiId: !Ref APIGatewayRestAPI
      Description: Paint For Me API Deployment
  APIGatewayStage:
    Type: AWS::ApiGateway::Stage
    Properties:
      DeploymentId: !Ref APIGatewayDeployment
      RestApiId: !Ref APIGatewayRestAPI
      StageName: !Ref APIGatewayStageName
      Description: Paint For Me API Stage v1
  APIGatewayPermission:
    Type: AWS::Lambda::Permission
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !GetAtt APIGatewayToAmazonRekognitionLambdaFunction.Arn
      Principal: apigateway.amazonaws.com
  APIGatewayRestAPI:
    Type: AWS::ApiGateway::RestApi
    Properties:
      Description: Paint For Me API Gateway
      EndpointConfiguration:
        Types:
          - REGIONAL
      Name: !Ref APIGatewayName
  APIGatewayResource:
    Type: AWS::ApiGateway::Resource
    Properties:
      ParentId: !GetAtt APIGatewayRestAPI.RootResourceId
      PathPart: paint-for-me
      RestApiId: !Ref APIGatewayRestAPI
  APIGatewayMethod:
    Type: AWS::ApiGateway::Method
    Properties:
      ResourceId: !Ref APIGatewayResource
      RestApiId: !Ref APIGatewayRestAPI
      OperationName: !Ref APIGatewayOperationName
      AuthorizationType: NONE
      ApiKeyRequired: false
      HttpMethod: POST
      Integration:
        Type: AWS_PROXY
        IntegrationHttpMethod: POST
        PassthroughBehavior: WHEN_NO_MATCH
        Uri: !Sub
          - arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${lambdaArn}/invocations
          - lambdaArn: !GetAtt APIGatewayToAmazonRekognitionLambdaFunction.Arn
  ReplaceInS3BucketLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: "/"
      Policies:
        - PolicyName: ReplaceInS3BucketLambdaFunctionPolicies
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - s3:PutObject
                Resource: !Sub "arn:aws:s3:::${WebsiteS3Bucket}/*"
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: "*"
  ReplaceInS3BucketLambdaInvoke:
    Type: AWS::CloudFormation::CustomResource
    DependsOn:
      - GitHubToS3LambdaInvoke
      - ReplaceInS3BucketLambdaFunction
    Version: "1.0"
    Properties:
      ServiceToken: !GetAtt ReplaceInS3BucketLambdaFunction.Arn
  ReplaceInS3BucketLambdaFunction:
    Type: AWS::Lambda::Function
    DependsOn: APIGatewayRestAPI
    Properties:
      Runtime: python3.9
      Timeout: 60
      Handler: index.lambda_handler
      Role: !GetAtt ReplaceInS3BucketLambdaRole.Arn
      Environment:
        Variables:
          FILE_NAME: !Ref FileWithAPIGatewayInvokeURL
          BUCKET_NAME: !Ref WebsiteS3Bucket
          VALUES_TO_REPLACE: API_GATEWAY_URL
          VALUES_TO_BE_REPLACED: !Sub https://${APIGatewayRestAPI}.execute-api.${AWS::Region}.amazonaws.com/${APIGatewayStageName}
      Code:
        ZipFile: |
          import os
          import cfnresponse
          import boto3

          FILE_NAME = os.environ['FILE_NAME']
          BUCKET_NAME = os.environ['BUCKET_NAME']
          VALUES_TO_REPLACE = os.environ['VALUES_TO_REPLACE'].split(",")
          VALUES_TO_BE_REPLACED = os.environ['VALUES_TO_BE_REPLACED'].split(",")

          TMP_FILE_PATH = '/tmp/' + FILE_NAME

          s3 = boto3.resource('s3')

          def download_file():
            bucket = s3.Bucket(BUCKET_NAME)
            bucket.download_file(FILE_NAME, TMP_FILE_PATH)

          def read_file():
              with open(TMP_FILE_PATH, 'r') as file:
                filedata = file.read()
              return filedata

          def reaplce_values_in_file(filedata):
              for index, toReplace in enumerate(VALUES_TO_REPLACE):
                toBeReplaced = VALUES_TO_BE_REPLACED[index]
                filedata = filedata.replace(toReplace, toBeReplaced)
                print("Changed value from: " + toReplace + " to: " + toBeReplaced + " in file: " + FILE_NAME)
              return filedata

          def save_new_values_to_file(filedata):
              with open(TMP_FILE_PATH, 'w') as file:
                file.write(filedata)

          def upload_updated_file_to_s3():
              s3.Object(BUCKET_NAME, FILE_NAME).put(Body=open(TMP_FILE_PATH, 'rb').read())

          def lambda_handler(event, context):
              responseData = {}
              requestType = event['RequestType']
              try:
                if requestType == 'Create':
                  download_file()
                  filedata = read_file()
                  filedata = reaplce_values_in_file(filedata)
                  save_new_values_to_file(filedata)
                  upload_updated_file_to_s3()
                  print("Successfully updated file: " + FILE_NAME + " in bucket: " + BUCKET_NAME)
                cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
              except Exception as e:
                print("Exception when updated file: " + FILE_NAME + " in bucket: " + BUCKET_NAME)
                print(e)
                cfnresponse.send(event, context, cfnresponse.FAILED, responseData)
  ImagesS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref ImagesBucketName
  APIGatewayToAmazonRekognitionLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: "/"
      Policies:
        - PolicyName: APIGatewayToAmazonRekognitionLambdaFunctionPolicies
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - s3:*
                Resource:
                  - !Sub "arn:aws:s3:::${ImagesBucketName}"
                  - !Sub "arn:aws:s3:::${ImagesBucketName}/*"
              - Effect: Allow
                Action:
                  - rekognition:*
                Resource: "*"
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: "*"
  APIGatewayToAmazonRekognitionLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Runtime: python3.9
      Timeout: 30
      Handler: index.lambda_handler
      Role: !GetAtt APIGatewayToAmazonRekognitionLambdaRole.Arn
      Environment:
        Variables:
          BUCKET_NAME: !Ref ImagesS3Bucket
          MAX_LABELS: !Ref MaxNumberOfLabels
          MIN_CONFIDENCE: !Ref MinConfidence
      Code:
        ZipFile: |
          import json
          import os
          import boto3
          import datetime
          import base64

          BUCKET_NAME = os.environ['BUCKET_NAME']
          MAX_LABELS = os.environ['MAX_LABELS']
          MIN_CONFIDENCE = os.environ['MIN_CONFIDENCE']

          s3 = boto3.resource('s3')
          rekognition = boto3.client('rekognition')

          def save_to_s3(fileName, image):
              fileNameWithExtension = fileName + ".png"
              image = image.replace("data:image/png;base64,", "")
              s3.Object(BUCKET_NAME, fileNameWithExtension).put(Body=base64.b64decode(image))
              print("Successfully saved file: " + fileNameWithExtension + " to S3 bucket: " + BUCKET_NAME)
              return fileNameWithExtension

          def analyze_image(fileNameWithExtension):
              return rekognition.detect_labels(Image = {"S3Object": {"Bucket": BUCKET_NAME, "Name": fileNameWithExtension}}, MaxLabels=int(MAX_LABELS), MinConfidence=int(MIN_CONFIDENCE))

          def lambda_handler(event, context):
              print("Received request: ")
              print(json.loads(event['body']))
              data = json.loads(event['body'])
              image = data['image']
              now = datetime.datetime.now()
              fileName = f'rekognition_job_{now:%Y-%m-%d-%H-%M}'
              response = {
                      "statusCode": 500,
                      "body": json.dumps( {"Status": "Failed"} ),
                      "headers": { "Access-Control-Allow-Origin" : "*" }
                  }
              fileNameWithExtension = {}
              try:
                  fileNameWithExtension = save_to_s3(fileName, image)
              except Exception as e:
                  print("Exception when saving image to S3 bucket: " + BUCKET_NAME)
                  print(e)
              try:
                  rekognitionResponse = analyze_image(fileNameWithExtension)
                  print("Rekognition response: ")
                  print(rekognitionResponse)
                  response = {
                      "statusCode": 200,
                      "body": json.dumps(rekognitionResponse),
                      "headers": { "Access-Control-Allow-Origin" : "*" }
                  } 
              except Exception as e:
                  print("Exception when calling Rekognition")
                  print(e)
              return response
  S3BucketCleanerLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: "/"
      Policies:
        - PolicyName: S3BucketCleanerLambdaFunctionPolicies
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - s3:ListBucket
                Resource:
                  - !Sub "arn:aws:s3:::${WebsiteBucketName}"
                  - !Sub "arn:aws:s3:::${ImagesBucketName}"
              - Effect: Allow
                Action:
                  - s3:DeleteObject
                Resource:
                  - !Sub "arn:aws:s3:::${WebsiteBucketName}/*"
                  - !Sub "arn:aws:s3:::${ImagesBucketName}/*"
  S3BucketCleanerLambdaInvoke:
    Type: AWS::CloudFormation::CustomResource
    Version: "1.0"
    Properties:
      ServiceToken: !GetAtt S3BucketCleanerLambdaFunction.Arn
  S3BucketCleanerLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Runtime: python3.9
      Timeout: 60
      Handler: index.lambda_handler
      Role: !GetAtt S3BucketCleanerLambdaRole.Arn
      Environment:
        Variables:
          BUCKETS_TO_CLEAN:
            !Join [",", [!Ref WebsiteS3Bucket, !Ref ImagesS3Bucket]]
      Code:
        ZipFile: |
          import os.path
          import boto3
          import cfnresponse

          BUCKETS_TO_CLEAN = os.environ['BUCKETS_TO_CLEAN'].split(",")

          s3 = boto3.resource('s3')

          def clear_bucket(bucket):
              s3.Bucket(bucket).objects.all().delete()

          def lambda_handler(event, context):
              responseData = {}
              if event['RequestType'] == 'Delete':
                  for bucket in BUCKETS_TO_CLEAN:
                      try:
                          clear_bucket(bucket)
                          print("Successfully cleared bucket: " + bucket)
                          cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
                      except Exception as e:
                          print('Exception when cleaning bucket: ' + bucket)
                          print(e)
                          cfnresponse.send(event, context, cfnresponse.FAILED, responseData)
              else:
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
Outputs:
  WebsiteUrl:
    Description: Website Url
    Value: !GetAtt WebsiteS3Bucket.WebsiteURL
  APIGatewayInvokeURL:
    Description: API invoke URL
    Value: !Sub https://${APIGatewayRestAPI}.execute-api.${AWS::Region}.amazonaws.com/${APIGatewayStageName}
